{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intellitrend-global/google_hackathon_bq_ai/blob/main/process_reports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåç ESG & üí≤Financial Intelligence Platform\n",
        "## AI-Powered Analysis of Corporate Reports (ESG And Annual)\n",
        "\n",
        "**üéØ What this does:**\n",
        "- Automatically processes PDF reports from Google Cloud Storage\n",
        "- Uses Gemini 2.5 Pro to extract financial & ESG metrics\n",
        "- Generates forecasts using Google's TimesFM 2.0 model\n",
        "- Analyzes companies: Amgen, Novartis, Target\n",
        "\n",
        "**üìä Features:**\n",
        "- ‚úÖ Automated PDF processing from Cloud Storage\n",
        "- ‚úÖ AI-powered data extraction (Financial + ESG metrics)\n",
        "- ‚úÖ Revenue forecasting with TimesFM 2.0\n",
        "- ‚úÖ Multi-company comparative analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "B4mF9BKbVXq9"
      },
      "id": "B4mF9BKbVXq9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîëSetup & Authentication"
      ],
      "metadata": {
        "id": "KdGXBO2wqGdM"
      },
      "id": "KdGXBO2wqGdM"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üåü Welcome to the ESG & Financial Intelligence Platform!\")\n",
        "print(\"üîß Setting up environment...\")\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q bigframes google-cloud-bigquery plotly seaborn\n",
        "\n",
        "# Import libraries\n",
        "import bigframes.pandas as bpd\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "print(\"‚úÖ Authentication complete!\")\n",
        "print(\"‚úÖ Libraries installed!\")"
      ],
      "metadata": {
        "id": "MsdBozKaVcBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3952bc-5ca1-4401-da2c-0b2d26a42292"
      },
      "id": "MsdBozKaVcBV",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåü Welcome to the ESG & Financial Intelligence Platform!\n",
            "üîß Setting up environment...\n",
            "‚úÖ Authentication complete!\n",
            "‚úÖ Libraries installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Intializing Parameters"
      ],
      "metadata": {
        "id": "G8ZIpU_YqTKm"
      },
      "id": "G8ZIpU_YqTKm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the below with other company names from this list:\n",
        "# novartis, amgen, target, bankofmontreal, lloyd, wellsfargo\n",
        "# we can use an array / list if we need to process more than one company\n",
        "\n",
        "company1 = \"novartis\"\n",
        "company2 =\"unitedhealth\"\n",
        "company3 = \"amgen\"\n",
        "\n",
        "DATA_FILES_PATH=\"gs://report_insights\"\n",
        "\n",
        "PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "PROJECT_LOCATION=\"US\" # Others are EU, ASIA\n",
        "CLOUD_RES_CONN = \"ghack_conn\" #must be all small case\n",
        "\n",
        "\n",
        "DATASET_ID = \"db_reports_insights_annual_esg\" #Name of dataset to be created in BQ\n",
        "\n",
        "OBJ_TABLE_ID = \"all_reports_obj_table_metadata\" #Objec table name. That holds the metadata of the source files in GCS\n",
        "RAW_TABLE_ID=\"all_reports_ai_text_raw\"   # the output text that gets extracted based on prmpt - using ML.GENERATE_TEXT\n",
        "\n",
        "CURATED_TABLE_ID=\"all_reports_ai_text_curated\" # response_text extracted from JSON output\n",
        "CURATED2_TABLE_ID=\"all_reports_ai_text_curated2\" # the output text that gets extracted based on prmpt - using AI.GENERATE (An alternate way - for comparison)\n",
        "\n",
        "FINAL_TABLE_ID=\"all_reports_ai_text_final\" # output metrics info from the curated table - using AI.GENERATE_TABLE\n",
        "\n",
        "METRICS_TABLE_ID = \"all_reports_metrics\"  # format the output final table\n",
        "FORECAST_TABLE_ID=\"all_reports_forecast\" # forecast table from the formatted-output\n",
        "\n",
        "QUALIFIED_CLOUD_RES_CONN = f\"{PROJECT_ID}.{PROJECT_LOCATION}.{CLOUD_RES_CONN}\"\n",
        "\n",
        "QUALIFIED_OBJ_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{OBJ_TABLE_ID}\"\n",
        "QUALIFIED_RAW_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{RAW_TABLE_ID}\"\n",
        "\n",
        "QUALIFIED_CURATED_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{CURATED_TABLE_ID}\"\n",
        "QUALIFIED_CURATED2_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{CURATED2_TABLE_ID}\"\n",
        "\n",
        "QUALIFIED_METRICS_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{METRICS_TABLE_ID}\"\n",
        "\n",
        "QUALIFIED_FINAL_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{FINAL_TABLE_ID}\"\n",
        "QUALIFIED_FORECAST_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{FORECAST_TABLE_ID}\"\n",
        "\n",
        "MODEL_ENDPOINT=\"gemini-2.5-pro\" # or any other gemini model\n",
        "MODEL_NAME=\"gemini_model_25pro\"\n",
        "QUALIFIED_MODEL_ID=f\"{PROJECT_ID}.{DATASET_ID}.{MODEL_NAME}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Bigframes setup ---\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = PROJECT_LOCATION"
      ],
      "metadata": {
        "id": "j9wXa542JAad"
      },
      "id": "j9wXa542JAad",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèóÔ∏è Project Configuration"
      ],
      "metadata": {
        "id": "xEZ9AjxmqYPW"
      },
      "id": "xEZ9AjxmqYPW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure BigFrames\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = PROJECT_LOCATION\n",
        "\n",
        "# Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(f\"‚úÖ Project configured: {PROJECT_ID}\")\n",
        "print(\"‚úÖ BigFrames ready for action!\")"
      ],
      "metadata": {
        "id": "Jq2mXY6ZWC29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29e19e0-58a9-41df-d726-00ed15e43161"
      },
      "id": "Jq2mXY6ZWC29",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Project configured: intellitrend-project-dev\n",
            "‚úÖ BigFrames ready for action!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîóCreate Cloud Resource Connection"
      ],
      "metadata": {
        "id": "ibVYprE2qbYa"
      },
      "id": "ibVYprE2qbYa"
    },
    {
      "cell_type": "code",
      "source": [
        "!bq mk \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --connection_type=CLOUD_RESOURCE \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN}"
      ],
      "metadata": {
        "id": "-5dp4Ss5BmI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ec154a-71d2-4574-cc80-c7044da8edbc"
      },
      "id": "-5dp4Ss5BmI_",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigQuery error in mk operation: Already Exists: Connection\n",
            "projects/573553606303/locations/us/connections/ghack_conn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üÜîFetch Service Account associated with the Cloud Res Connection"
      ],
      "metadata": {
        "id": "TJA-cM8fqkea"
      },
      "id": "TJA-cM8fqkea"
    },
    {
      "cell_type": "code",
      "source": [
        "SERVICE_ACCT = !bq show --format=prettyjson \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN} | grep \"serviceAccountId\" | cut -d '\"' -f 4\n",
        "\n",
        "SERVICE_ACCT_EMAIL = SERVICE_ACCT[0]  # first (and only) line\n",
        "print(SERVICE_ACCT_EMAIL)"
      ],
      "metadata": {
        "id": "Br8HeQf8COGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed19448-4fe8-4e1b-f560-f569fe3bb576"
      },
      "id": "Br8HeQf8COGv",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bqcx-573553606303-2s0n@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üë•Give the below roles to the Conn Service Account:\n",
        "  * objectViewer and  \n",
        "  * aiplatformUser\n",
        "\n"
      ],
      "metadata": {
        "id": "wLTg-1olqrA5"
      },
      "id": "wLTg-1olqrA5"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Use $SERVICE_ACCT_EMAIL so the Python variable expands in the shell\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/storage.objectViewer\" \\\n",
        "    --format=none\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/aiplatform.user\" \\\n",
        "    --format=none\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/bigquery.connectionUser\" \\\n",
        "    --format=none\n",
        "\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/run.invoker\" \\\n",
        "    --format=none\n",
        "\n",
        "\n",
        "# Wait ~60 seconds for IAM updates to propagate\n",
        "# time.sleep(60)"
      ],
      "metadata": {
        "id": "TOoTQl_iDVNQ",
        "outputId": "e2b54c1e-38af-4b50-f1cc-c386b50fe1fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TOoTQl_iDVNQ",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated IAM policy for project [intellitrend-project-dev].\n",
            "Updated IAM policy for project [intellitrend-project-dev].\n",
            "Updated IAM policy for project [intellitrend-project-dev].\n",
            "Updated IAM policy for project [intellitrend-project-dev].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚ú¶ Create the Gemini Model"
      ],
      "metadata": {
        "id": "zoGn5y3prEO1"
      },
      "id": "zoGn5y3prEO1"
    },
    {
      "cell_type": "code",
      "source": [
        "# ü§ñ Step 0a: Create Gemini 2.5 Pro Model\n",
        "print(\"ü§ñ Creating Gemini 2.5 Pro model...\")\n",
        "\n",
        "create_model_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{QUALIFIED_MODEL_ID}`\n",
        "REMOTE WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "OPTIONS (ENDPOINT = '{MODEL_ENDPOINT}');\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(create_model_sql)\n",
        "    job.result()\n",
        "    print(\"üéâ Gemini 2.5 Pro model created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Model creation issue: {e}\")"
      ],
      "metadata": {
        "id": "8H-B2sKyNRYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d525ae-13a8-49b4-bc68-4681b8a5b7ef"
      },
      "id": "8H-B2sKyNRYI",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Creating Gemini 2.5 Pro model...\n",
            "üéâ Gemini 2.5 Pro model created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ùÑú Create **Object Table** for PDF Reports"
      ],
      "metadata": {
        "id": "uN-WN3hwrJQO"
      },
      "id": "uN-WN3hwrJQO"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"üìÅ Creating external table(Object Table): '{OBJ_TABLE_ID}' for PDF reports...\")\n",
        "\n",
        "create_external_table_sql = f\"\"\"\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{QUALIFIED_OBJ_TABLE_ID}`\n",
        "WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "OPTIONS (\n",
        "  object_metadata = 'SIMPLE',\n",
        "  uris = ['{DATA_FILES_PATH}/{company1}/*', '{DATA_FILES_PATH}/{company2}/*', '{DATA_FILES_PATH}/{company3}/*']\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# Uncomment to process a single file for testing\n",
        "\n",
        "# create_external_table_sql = f\"\"\"\n",
        "# CREATE OR REPLACE EXTERNAL TABLE `{QUALIFIED_OBJ_TABLE_ID}`\n",
        "# WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "# OPTIONS (\n",
        "#   object_metadata = 'SIMPLE',\n",
        "#   uris = ['{DATA_FILES_PATH}/{company1}/{company1}_annualreport_2020.pdf']\n",
        "# );\n",
        "# \"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(create_external_table_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ External table created successfully!\")\n",
        "\n",
        "    # Check what files we have\n",
        "    check_files_sql = f\"SELECT uri, size FROM `{QUALIFIED_OBJ_TABLE_ID}`  \"\n",
        "    files_df = bpd.read_gbq(check_files_sql)\n",
        "    print(f\"üìÑ Found {len(files_df)} files in storage\")\n",
        "    print(\"Sample files:\")\n",
        "    print(files_df.head())\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Note: {e}\")\n",
        "    print(\"   Make sure your GCS bucket and connection are set up correctly\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "7YQ_Q-LjIF0U",
        "outputId": "0ee76232-f735-47b3-ef76-68e1f91db586"
      },
      "id": "7YQ_Q-LjIF0U",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Creating external table(Object Table): 'all_reports_obj_table_metadata' for PDF reports...\n",
            "‚úÖ External table created successfully!\n",
            "üìÑ Found 33 files in storage\n",
            "Sample files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job f30e5bf6-0a8f-4cc1-ab6c-3fee1f20af94 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=intellitrend-project-dev&j=bq:US:f30e5bf6-0a8f-4cc1-ab6c-3fee1f20af94&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 uri     size\n",
            "0  gs://report_insights/novartis/novartis_annualr...  4228147\n",
            "1  gs://report_insights/novartis/novartis_annualr...  3767323\n",
            "2  gs://report_insights/novartis/novartis_annualr...  3598595\n",
            "3  gs://report_insights/novartis/novartis_annualr...  3990455\n",
            "4  gs://report_insights/novartis/novartis_annualr...  3861068\n",
            "\n",
            "[5 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  ÷é Extract Financial & ESG Data - **Using ML.GENERATE_TEXT**"
      ],
      "metadata": {
        "id": "vyuEomOKrU84"
      },
      "id": "vyuEomOKrU84"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"÷é Processing PDFs with {MODEL_NAME}...\")\n",
        "print(f\"This analyzes {company1}, {company2}, and {company3} reports...\")\n",
        "\n",
        "generate_text_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_RAW_TABLE_ID}` AS (\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `{QUALIFIED_MODEL_ID}`,\n",
        "    TABLE `{QUALIFIED_OBJ_TABLE_ID}`,\n",
        "    STRUCT(\n",
        "      '''\n",
        "        You are an expert ESG and Financial analyst. Use only the information provided in the document to answer.\n",
        "        Fetch Financial and Sustainability details and metrics from text, tabular and image data for each PDF.\n",
        "\n",
        "      ''' AS prompt,\n",
        "\n",
        "      0 AS temperature,\n",
        "      8092 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "WHERE uri like '%{company1}%' or uri like '%{company2}%' or  uri like '%{company3}%'\n",
        ");\n",
        "\"\"\"\n",
        "#print(\"\\n\\n the SQL \\n\\n\", generate_text_sql)\n",
        "try:\n",
        "    print(\"‚è≥ Processing... \")\n",
        "    job = client.query(generate_text_sql)\n",
        "    job.result()\n",
        "\n",
        "    # Check results\n",
        "    check_sql = f\"SELECT COUNT(*) as processed_files FROM `{QUALIFIED_RAW_TABLE_ID}`\"\n",
        "    result = client.query(check_sql).result()\n",
        "    count = list(result)[0][0]\n",
        "    print(f\"‚úÖ Successfully processed {count} files!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Processing issue: {e}\")"
      ],
      "metadata": {
        "id": "BHfkpWRwZ7Lw",
        "outputId": "f99f5a04-cc1d-4f1d-ae0b-d39c6f471595",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BHfkpWRwZ7Lw",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "÷é Processing PDFs with gemini_model_25pro...\n",
            "This analyzes novartis, unitedhealth, and amgen reports...\n",
            "‚è≥ Processing... \n",
            "‚úÖ Successfully processed 33 files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßπ Extract **Clean** Text Response"
      ],
      "metadata": {
        "id": "Ct2UPyXMrnbD"
      },
      "id": "Ct2UPyXMrnbD"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üßπ Cleaning and extracting response text...\")\n",
        "\n",
        "curate_results_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_CURATED_TABLE_ID}` AS\n",
        "SELECT *,\n",
        "  ARRAY_TO_STRING(\n",
        "    ARRAY(\n",
        "      SELECT JSON_VALUE(part, '$.text')\n",
        "      FROM UNNEST(JSON_QUERY_ARRAY(\n",
        "        JSON_QUERY(ml_generate_text_result, '$.candidates[0].content.parts')\n",
        "      )) AS part\n",
        "    ),\n",
        "    ''\n",
        "  ) AS response_text\n",
        "FROM\n",
        "  `{QUALIFIED_RAW_TABLE_ID}`;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(curate_results_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ Response text extracted and cleaned!\")\n",
        "\n",
        "    # Show sample of extracted text\n",
        "    sample_sql = f\"\"\"\n",
        "    SELECT uri, LEFT(response_text, 200) as sample_text\n",
        "    FROM `{QUALIFIED_CURATED_TABLE_ID}`\n",
        "    LIMIT 3\n",
        "    \"\"\"\n",
        "    sample_df = bpd.read_gbq(sample_sql)\n",
        "    print(\"\\nüìù Sample extracted text:\")\n",
        "    for _, row in sample_df.iterrows():\n",
        "        print(f\"File: {row['uri']}\")\n",
        "        print(f\"Text: {row['sample_text']}...\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Text extraction issue: {e}\")"
      ],
      "metadata": {
        "id": "_hLB42ZHW1mV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3a9383-56cc-4a75-ea6d-7479ef9b4b14"
      },
      "id": "_hLB42ZHW1mV",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaning and extracting response text...\n",
            "‚úÖ Response text extracted and cleaned!\n",
            "\n",
            "üìù Sample extracted text:\n",
            "File: gs://report_insights/amgen/amgen_sustainabilityreport_2024.pdf\n",
            "Text: Here are the financial and sustainability details from the Amgen 2024 Sustainability Highlights Report.\n",
            "\n",
            "### Financial Details\n",
            "\n",
            "| Metric | 2024 | 2023 | Source |\n",
            "| --- | --- | --- | --- |\n",
            "| **Total Re...\n",
            "\n",
            "File: gs://report_insights/amgen/amgen_sustainabilityreport_2023.pdf\n",
            "Text: ```json\n",
            "{\"company_name\": \"Amgen\", \"year\": 2023, \"url\": \"https://www.amgen.com/sustainability/2023-esg-report\", \"source_file\": \"Amgen 2023 ESG Report\", \"financial_and_sustainability_details\": {\"General...\n",
            "\n",
            "File: gs://report_insights/novartis/novartis_sustainability_2021.pdf\n",
            "Text: Based on the \"Novartis in Society Integrated Report 2021,\" here is a summary of the key financial and sustainability details.\n",
            "\n",
            "### Sustainability and ESG\n",
            "\n",
            "#### **Overall ESG Strategy & Performance**\n",
            "-...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "print(f\"÷é Processing PDFs with {MODEL_NAME}...\")\n",
        "print(f\"This analyzes {company1}, {company2}, and {company3} reports...\")\n",
        "\n",
        "user_question=\"'What is the total revenue this year?'\"\n",
        "user_question=\"\"\n",
        "selected_company = \"novartis\"\n",
        "selected_year = \"2024\"\n",
        "selected_report_type=\"annual\"\n",
        "\n",
        "if selected_report_type==\"annual\":\n",
        "  default_questions=\"\"\"\n",
        "CONCAT('Answer all the below questions:',\n",
        "'Read the data and fetch the below details:',\n",
        "'Financial Performance',\n",
        "'What is the total revenue this year?',\n",
        "'How has revenue changed compared to last year?',\n",
        "'What is the net profit or loss?',\n",
        "'How have the earnings per share (EPS) changed?',\n",
        "'Are gross margins improving or declining?',\n",
        "'Are operating margins stable or volatile?',\n",
        "'How has net margin shifted year over year?',\n",
        "'Is cash flow from operations positive and consistent?',\n",
        "'How much free cash flow is available?',\n",
        "'How are working capital levels trending?',\n",
        "\n",
        "'Balance Sheet & Liquidity',\n",
        "'What is the total debt level?',\n",
        "'Is the debt-to-equity ratio rising or falling?',\n",
        "'Does the company have enough liquidity to cover short-term liabilities?',\n",
        "'What is the current ratio and quick ratio?',\n",
        "'How much cash and equivalents are available?',\n",
        "'Are interest expenses sustainable?',\n",
        "'How sensitive is the company to interest rate changes?',\n",
        "'What is the level of contingent liabilities?',\n",
        "\n",
        "'Business Strategy',\n",
        "'What are the company‚Äôs core growth initiatives?',\n",
        "'Is management investing in new markets or products?',\n",
        "'How much is spent on research and development (R&D)?',\n",
        "'Are acquisitions or divestitures planned?',\n",
        "'Is the company expanding geographically?',\n",
        "'What is the company competitive advantage?',\n",
        "'Is the advantage sustainable against competitors?',\n",
        "'Is digital transformation a core part of the strategy?',\n",
        "\n",
        "'Risk Factors',\n",
        "'What macroeconomic risks affect the business?',\n",
        "'What industry-specific risks are highlighted?',\n",
        "'What operational risks are disclosed?',\n",
        "'Are supply chain risks material?',\n",
        "'Are legal or regulatory risks mentioned?',\n",
        "'How is foreign exchange risk managed?',\n",
        "'How dependent is revenue on a few customers?',\n",
        "'Are raw material price risks significant?',\n",
        "\n",
        "'Governance & Leadership',\n",
        "'Is the board majority independent?',\n",
        "'How many women or minorities are on the board?',\n",
        "'Is executive compensation performance-linked?',\n",
        "'Does management own significant equity?',\n",
        "'Are shareholder rights well protected?',\n",
        "'Is succession planning disclosed?',\n",
        "'Has management delivered on past promises?',\n",
        "'Is the auditor independent and credible?',\n",
        "\n",
        "'Shareholder Value',\n",
        "'Is the company paying dividends?',\n",
        "'Is the dividend payout sustainable?',\n",
        "'Is the dividend policy clear?',\n",
        "'Are share buybacks taking place?',\n",
        "'Is return on equity (ROE) improving?',\n",
        "'Is return on assets (ROA) stable?',\n",
        "'Has shareholder equity grown consistently?',\n",
        "'What is the earnings guidance for next year?'\n",
        ")\n",
        "\"\"\"\n",
        "else:\n",
        "  default_questions=\"\"\"\n",
        "CONCAT('Answer all the below questions:',\n",
        "'Read the data and fetch the below details:',\n",
        "'Investor Questions ‚Äì Sustainability Reports',\n",
        "\n",
        "'Environmental',\n",
        "'What is the total Scope 1 emissions?',\n",
        "'What is the total Scope 2 emissions?',\n",
        "'What is the total Scope 3 emissions?',\n",
        "'Are science-based targets disclosed?',\n",
        "'Has the company committed to net-zero?',\n",
        "'What percentage of energy is renewable?',\n",
        "'Is energy efficiency improving year over year?',\n",
        "'What is the total water withdrawal?',\n",
        "'What is water recycled or reused?',\n",
        "'Is the company exposed to water stress?',\n",
        "'How much total waste is generated?',\n",
        "'How much waste is recycled or diverted from landfill?',\n",
        "'Are hazardous waste levels disclosed?',\n",
        "'How sustainable are raw material sourcing practices?',\n",
        "'Are biodiversity risks addressed?',\n",
        "\n",
        "'Social',\n",
        "'What is the total workforce size?',\n",
        "'What percentage of employees are women?',\n",
        "'What percentage of leadership roles are held by women?',\n",
        "'What is minority representation in the workforce?',\n",
        "'What is the employee turnover rate?',\n",
        "'How many workplace injuries occurred?',\n",
        "'What is the lost-time injury frequency rate?',\n",
        "'Are labor rights respected across the supply chain?',\n",
        "'Is child labor risk disclosed in supply chains?',\n",
        "'Are employee training hours increasing per year?',\n",
        "'Are wages above local living wage levels?',\n",
        "'Is there employee engagement survey data?',\n",
        "'What community development initiatives exist?',\n",
        "'What philanthropic contributions were made?',\n",
        "'Is there disclosure on data privacy and cybersecurity?',\n",
        "\n",
        "'Governance (ESG-specific)',\n",
        "'Is there a dedicated board ESG committee?',\n",
        "'How often does the board review ESG matters?',\n",
        "'Is ESG risk included in enterprise risk management?',\n",
        "'Is executive compensation tied to ESG goals?',\n",
        "'Are ESG targets linked to management incentives?',\n",
        "'Is ESG performance externally assured?',\n",
        "'Are ESG disclosures aligned with GRI or SASB?',\n",
        "'Does the company report under TCFD or ISSB?',\n",
        "'Is CDP reporting publicly available?',\n",
        "'Are stakeholder engagement practices disclosed?',\n",
        "\n",
        "'Risk & Opportunity',\n",
        "'What are the identified physical climate risks?',\n",
        "'What are the identified transition risks?',\n",
        "'Is there disclosure on carbon pricing exposure?',\n",
        "'How dependent is revenue on carbon-intensive activities?',\n",
        "'What sustainability-linked opportunities are identified?',\n",
        "'Are green products or services generating revenue?',\n",
        "'Is access to sustainable finance increasing?',\n",
        "'Are suppliers evaluated for ESG performance?',\n",
        "'Are ESG clauses included in supplier contracts?',\n",
        "'Is there disclosure on product lifecycle impacts?'\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# -------------------------------\n",
        "# Build prompt\n",
        "# -------------------------------\n",
        "if user_question.strip():\n",
        "    question_block = f\"{user_question}\"\n",
        "else:\n",
        "    question_block = f\"{default_questions}\"\n",
        "\n",
        "\n",
        "\n",
        "generate_text_sql2 = f\"\"\"\n",
        " SELECT\n",
        "    response_text,\n",
        "    AI.GENERATE(\n",
        "    (\n",
        "      CONCAT({question_block}),\n",
        "    response_text),\n",
        "    connection_id => '{PROJECT_LOCATION}.{CLOUD_RES_CONN}',\n",
        "  endpoint => '{MODEL_ENDPOINT}'\n",
        ").result\n",
        "FROM `{QUALIFIED_CURATED_TABLE_ID}`\n",
        "WHERE (uri like '%{selected_company}%')\n",
        "AND uri like '%{selected_year}%'\n",
        "AND uri like '%{selected_report_type}%';\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#print(\"\\n\\n the SQL \\n\\n\", generate_text_sql)\n",
        "try:\n",
        "    print(\"‚è≥ Processing... \")\n",
        "    # job = client.query(generate_text_sql2)\n",
        "    # job.result()\n",
        "\n",
        "    sample_df2 = bpd.read_gbq(generate_text_sql2)\n",
        "    print(\"\\nüìù \\n\\n\\n**************************:\")\n",
        "    for _, row in sample_df2.iterrows():\n",
        "      text=row['result']\n",
        "      display(Markdown(text))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Processing issue: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "t9sZ4I_uO68m",
        "outputId": "7a49e4cb-1745-47a4-95ce-06719f9d23e3"
      },
      "id": "t9sZ4I_uO68m",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "÷é Processing PDFs with gemini_model_25pro...\n",
            "This analyzes novartis, unitedhealth, and amgen reports...\n",
            "‚è≥ Processing... \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4223700124.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# job.result()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0msample_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gbq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_text_sql2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìù \\n\\n\\n**************************:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_df2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/core/log_adapter.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# Log method parameters that are implemented in pandas but either missing (TypeError)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/pandas/io/api.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(query_or_table, index_col, columns, configuration, max_results, filters, use_cache, col_order, dry_run, allow_large_results)\u001b[0m\n\u001b[1;32m    224\u001b[0m ) -> bigframes.dataframe.DataFrame | pandas.Series:\n\u001b[1;32m    225\u001b[0m     \u001b[0m_set_default_session_location_if_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_or_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     return global_session.with_default_session(\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mbigframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gbq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mquery_or_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/core/global_session.py\u001b[0m in \u001b[0;36mwith_default_session\u001b[0;34m(func_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwith_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_global_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/core/log_adapter.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# Log method parameters that are implemented in pandas but either missing (TypeError)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/session/__init__.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(self, query_or_table, index_col, columns, configuration, max_results, filters, use_cache, col_order, dry_run, allow_large_results)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbf_io_bigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_or_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             return self._loader.read_gbq_query(  # type: ignore # for dry_run overload\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0mquery_or_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/session/loader.py\u001b[0m in \u001b[0;36mread_gbq_query\u001b[0;34m(self, query, index_col, columns, configuration, max_results, use_cache, filters, dry_run, force_total_order, allow_large_results)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;31m# TODO(b/420984164): We may want to set a page_size here to limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;31m# the number of results in the first jobs.query response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             rows = self._start_query_with_job_optional(\n\u001b[0m\u001b[1;32m   1017\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/session/loader.py\u001b[0m in \u001b[0;36m_start_query_with_job_optional\u001b[0;34m(self, sql, job_config, timeout)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \"\"\"\n\u001b[1;32m   1172\u001b[0m         \u001b[0mjob_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_job_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         rows, _ = bf_io_bigquery.start_query_with_client(\n\u001b[0m\u001b[1;32m   1174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bqclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bigframes/session/_io/bigquery/__init__.py\u001b[0m in \u001b[0;36mstart_query_with_client\u001b[0;34m(bq_client, sql, job_config, location, project, timeout, metrics, query_with_job, job_retry)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0madd_and_trim_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquery_with_job\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             results_iterator = bq_client.query_and_wait(\n\u001b[0m\u001b[1;32m    329\u001b[0m                 \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery_and_wait\u001b[0;34m(self, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results)\u001b[0m\n\u001b[1;32m   3660\u001b[0m                 \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3661\u001b[0m         \"\"\"\n\u001b[0;32m-> 3662\u001b[0;31m         return self._query_and_wait_bigframes(\n\u001b[0m\u001b[1;32m   3663\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3664\u001b[0m             \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_query_and_wait_bigframes\u001b[0;34m(self, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results, callback)\u001b[0m\n\u001b[1;32m   3706\u001b[0m         )\n\u001b[1;32m   3707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3708\u001b[0;31m         return _job_helpers.query_and_wait(\n\u001b[0m\u001b[1;32m   3709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mquery_and_wait\u001b[0;34m(client, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results, callback)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjob_retry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdo_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36mdo_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;31m# client._list_rows_from_query_results directly. Need to update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;31m# RowIterator to fetch destination table via the job ID if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             return _wait_or_cancel(\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0m_to_query_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mapi_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_job_helpers.py\u001b[0m in \u001b[0;36m_wait_or_cancel\u001b[0;34m(job, api_timeout, wait_timeout, retry, page_size, max_results, callback)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 )\n\u001b[1;32m    699\u001b[0m             )\n\u001b[0;32m--> 700\u001b[0;31m         query_results = job.result(\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0mpage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1704\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1673\u001b[0m                 \u001b[0;31m# jobs.getQueryResults hangs as long as it can to ensure we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 \u001b[0;31m# know when the query has finished as soon as possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reload_query_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreload_query_results_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m                 \u001b[0;31m# Even if the query is finished now according to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36m_reload_query_results\u001b[0;34m(self, retry, timeout, page_size, start_index)\u001b[0m\n\u001b[1;32m   1465\u001b[0m                 \u001b[0mtransport_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m         self._query_results = self._client._get_query_results(\n\u001b[0m\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_get_query_results\u001b[0;34m(self, job_id, retry, project, timeout_ms, location, timeout, page_size, start_index)\u001b[0m\n\u001b[1;32m   2111\u001b[0m         \u001b[0;31m# QueryJob.result()). So we don't need to poll here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         resource = self._call_api(\n\u001b[0m\u001b[1;32m   2114\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.getQueryResults\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             ):\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         response = self._make_request(\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, url, data, content_type, headers, target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         return self._do_request(\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36m_do_request\u001b[0;34m(self, method, url, headers, data, target_object, timeout)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mHTTP\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[0;32m--> 379\u001b[0;31m         return self.http.request(\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    538\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Extract Structured Metrics - **Using AI.GENERATE_TABLE**"
      ],
      "metadata": {
        "id": "7u1iCJairu6y"
      },
      "id": "7u1iCJairu6y"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üìä Generating structured financial and ESG metrics...\")\n",
        "\n",
        "generate_table_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_FINAL_TABLE_ID}` AS\n",
        "SELECT *,\n",
        "    DATE(CAST(fiscal_year AS STRING) || \"-01-01\") AS fiscal_year_date,\n",
        "    CASE\n",
        "        WHEN uri LIKE '%{company1}%' THEN '{company1}'\n",
        "        WHEN uri LIKE '%{company2}%' THEN '{company2}'\n",
        "        WHEN uri LIKE '%{company3}%' THEN '{company3}'\n",
        "    END as company_name_formatted\n",
        "FROM (\n",
        "    SELECT *\n",
        "    FROM AI.GENERATE_TABLE(\n",
        "        MODEL `{QUALIFIED_MODEL_ID}`,\n",
        "        (\n",
        "            SELECT CONCAT(\n",
        "                \"You are an expert financial analyst and ESG/Climate analyst. Extract all financial metrics and sustainability metrics and KPIs from the provided text into structured data. \",\n",
        "                \"For Annual reports, focus on getting the financial metrics. And for Sustainability reports focus on getting ESG metrics. \",\n",
        "                \"Normalize numbers by removing commas, spaces, or symbols and convert all money values to dollars. \",\n",
        "                \"TEXT: \",\n",
        "                response_text\n",
        "            ) AS prompt,\n",
        "            response_text as extracted_text,\n",
        "            uri AS uri\n",
        "        FROM `{QUALIFIED_CURATED_TABLE_ID}`\n",
        "        ),\n",
        "        STRUCT(\n",
        "            'uris STRING, report_type STRING, company_name STRING, fiscal_year INT64, revenue_millions FLOAT64, net_income_millions FLOAT64, total_assets_millions FLOAT64, total_liabilities_millions FLOAT64, equity_millions FLOAT64, eps_basic FLOAT64, eps_diluted FLOAT64, dividends_per_share FLOAT64, employee_count INT64, business_segments ARRAY<STRING>, total_ghg_emissions FLOAT64, scope_1_ghg_emissions FLOAT64, scope_2_ghg_emissions FLOAT64, scope_3_ghg_emissions FLOAT64, carbon_intensity FLOAT64, energy_consumption FLOAT64, renewable_energy_usage FLOAT64, water_consumption FLOAT64, waste_generated FLOAT64, waste_recycled FLOAT64, sustainable_financing FLOAT64, reporting_period STRING, page_references ARRAY<STRING>, contexts ARRAY<STRING>, verbatim_quotes ARRAY<STRING>'\n",
        "            AS output_schema,\n",
        "            8192 AS max_output_tokens,\n",
        "            0 AS temperature\n",
        "        )\n",
        "    ) t\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"‚è≥ Structuring data... This may take 3-4 minutes\")\n",
        "    job = client.query(generate_table_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ Structured metrics extracted successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Table generation issue: {e}\")"
      ],
      "metadata": {
        "id": "2QOTj5J1XUW4"
      },
      "id": "2QOTj5J1XUW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate **Metric Table**\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QAwsY7BWr0l1"
      },
      "id": "QAwsY7BWr0l1"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üîÆ Generating metrics table\")\n",
        "\n",
        "metrics_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_METRICS_TABLE_ID}` AS\n",
        "SELECT * FROM\n",
        "    ( SELECT\n",
        "        uri, fiscal_year,\n",
        "        extracted_text, company_name_formatted as company_name,\n",
        "        -- Determine report_type based on URI\n",
        "        CASE\n",
        "            WHEN LOWER(uri) LIKE '%annual%' THEN 'Annual'\n",
        "            WHEN LOWER(uri) LIKE '%sustainability%' THEN 'Sustainability'\n",
        "            ELSE 'Other'\n",
        "        END AS report_type,\n",
        "        fiscal_year_date,\n",
        "        reporting_period ,\n",
        "        -- Financial metrics: keep if Annual, else 0\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN revenue_millions ELSE 0 END AS revenue_millions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN net_income_millions ELSE 0 END AS net_income_millions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN total_assets_millions ELSE 0 END AS total_assets_millions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN total_liabilities_millions ELSE 0 END AS total_liabilities_millions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN equity_millions ELSE 0 END AS equity_millions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN dividends_per_share ELSE 0 END AS dividends_per_share,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN eps_basic ELSE 0 END AS eps_basic,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN eps_diluted ELSE 0 END AS eps_diluted,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN employee_count ELSE 0 END AS employee_count,\n",
        "        CASE WHEN LOWER(uri) LIKE '%annual%' THEN sustainable_financing ELSE 0 END AS sustainable_financing,\n",
        "\n",
        "        -- Sustainability metrics: keep if Sustainability report, else 0\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN carbon_intensity ELSE 0 END AS carbon_intensity,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN energy_consumption ELSE 0 END AS energy_consumption,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN renewable_energy_usage ELSE 0 END AS renewable_energy_usage,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN scope_1_ghg_emissions ELSE 0 END AS scope_1_ghg_emissions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN scope_2_ghg_emissions ELSE 0 END AS scope_2_ghg_emissions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN scope_3_ghg_emissions ELSE 0 END AS scope_3_ghg_emissions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN total_ghg_emissions ELSE 0 END AS total_ghg_emissions,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN water_consumption ELSE 0 END AS water_consumption,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN waste_generated ELSE 0 END AS waste_generated,\n",
        "        CASE WHEN LOWER(uri) LIKE '%sustainability%' THEN waste_recycled ELSE 0 END AS waste_recycled\n",
        "\n",
        "     FROM `{QUALIFIED_FINAL_TABLE_ID}`\n",
        "     ) t\n",
        "-- WHERE report_type != 'Annual';\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚è≥ fetching metrics...\")\n",
        "job = client.query(metrics_sql)\n",
        "job.result()\n",
        "print(\"‚úÖ Metrics table created successfully!\")"
      ],
      "metadata": {
        "id": "ThCi0WF28s_6"
      },
      "id": "ThCi0WF28s_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÆ Revenue Forecasting with AI.FORECAST & TimesFM 2.0\n"
      ],
      "metadata": {
        "id": "ysUQR9JfBTzt"
      },
      "id": "ysUQR9JfBTzt"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîÆ Generating revenue forecasts with TimesFM 2.0...\")\n",
        "\n",
        "forecast_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_FORECAST_TABLE_ID}` AS\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  AI.FORECAST(\n",
        "    TABLE `{QUALIFIED_METRICS_TABLE_ID}`,\n",
        "    data_col => 'revenue_millions',\n",
        "    timestamp_col => 'fiscal_year_date',\n",
        "    model => 'TimesFM 2.0',\n",
        "    id_cols => ['company_name'],\n",
        "    horizon => 5,\n",
        "    confidence_level => .95\n",
        "  )\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚è≥ Forecasting...\")\n",
        "job = client.query(forecast_sql)\n",
        "job.result()\n",
        "print(\"‚úÖ Forecast table created successfully!\")"
      ],
      "metadata": {
        "id": "QjS1OIZwmIZg"
      },
      "id": "QjS1OIZwmIZg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output 1\n",
        "### Financial/ESG Details for pre-defined questions for selected company and fiscal_year and report type"
      ],
      "metadata": {
        "id": "m94nToNTEGmE"
      },
      "id": "m94nToNTEGmE"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "\n",
        "# --- Load your BigQuery table ---\n",
        "#df = bpd.read_gbq(f\"{QUALIFIED_METRICS_TABLE_ID}\")\n",
        "metrics_sql1 = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{QUALIFIED_METRICS_TABLE_ID}`\n",
        "\"\"\"\n",
        "df = bpd.read_gbq(metrics_sql1)\n",
        "\n",
        "# --- Choose which report to display ---\n",
        "company = \"bankofmontreal\"\n",
        "year = 2021\n",
        "rtype = \"Annual\"   # \"Annual\" or \"Sustainability Report\"\n",
        "\n",
        "# --- Filter ---\n",
        "filtered = df[\n",
        "    (df[\"company_name\"] == company)\n",
        "    & (df[\"fiscal_year\"] == year)\n",
        "    & (df[\"report_type\"] == rtype)\n",
        "]\n",
        "\n",
        "# --- Display pretty ---\n",
        "if not filtered.empty:\n",
        "    text = filtered[\"extracted_text\"].iloc[0]\n",
        "    display(Markdown(text))\n",
        "else:\n",
        "    print(\"No report found for that selection.\")\n",
        "    # --- Grab the first row (or loop if multiple) ---\n",
        "    text = df[\"extracted_text\"].iloc[0]\n",
        "\n",
        "    # --- Pretty display in Colab ---\n",
        "    print(\"\\n\\n===========================================================================\\n\\n\")\n",
        "    display(Markdown(text))"
      ],
      "metadata": {
        "id": "GvZ-uUFN_ow6"
      },
      "id": "GvZ-uUFN_ow6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics = bpd.read_gbq(f\"{QUALIFIED_METRICS_TABLE_ID}\")\n"
      ],
      "metadata": {
        "id": "lgeWMew8bafj"
      },
      "id": "lgeWMew8bafj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Metrics Table as Pandas Dataframe\n",
        "* ## Colab offers AI tools to auto-generate plots on pandas\n",
        "* ## We can use: Gen-code, View recommended plots, Interactive\n",
        "* ## More results at the end of the page"
      ],
      "metadata": {
        "id": "i-kjTwSePPMi"
      },
      "id": "i-kjTwSePPMi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the dataset\n",
        "df = df_metrics[['fiscal_year', 'company_name', 'report_type',   'revenue_millions', 'net_income_millions',\n",
        "                 'total_assets_millions', 'employee_count',   'scope_1_ghg_emissions',\n",
        "                 'scope_2_ghg_emissions', 'scope_3_ghg_emissions', 'total_ghg_emissions' ]].to_pandas()\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "rWY0QYhxH9me"
      },
      "id": "rWY0QYhxH9me",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All the plots below, were auto generated by Colab Auto Gen feature - on a dataframe!"
      ],
      "metadata": {
        "id": "SLnu4VEiOG_Z"
      },
      "id": "SLnu4VEiOG_Z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ced445"
      },
      "source": [
        "# Task\n",
        "Analyze the provided dataframe `df` to extract insights across companies by analyzing and visualizing key financial and ESG metrics."
      ],
      "id": "e1ced445"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ed8d1a"
      },
      "source": [
        "## Analyze net income\n",
        "\n",
        "### Subtask:\n",
        "Visualize and compare the net income trends across companies over the available years.\n"
      ],
      "id": "b8ed8d1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35557628"
      },
      "source": [
        "**Reasoning**:\n",
        "Filter the dataframe to include only annual reports and then group by company and fiscal year to calculate the sum of net income. This prepares the data for plotting the net income trend across companies.\n",
        "\n"
      ],
      "id": "35557628"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf2a4bf8"
      },
      "source": [
        "# Filter only annual reports\n",
        "df_filtered = df_metrics[df_metrics[\"report_type\"].str.lower() == \"annual\"]\n",
        "\n",
        "# Group by company and year\n",
        "df_grouped = df_filtered.groupby([\"company_name\", \"fiscal_year\"])[\n",
        "    \"net_income_millions\"\n",
        "].sum().reset_index()\n",
        "\n",
        "# Get unique values\n",
        "companies = df_grouped[\"company_name\"].unique().tolist()\n",
        "years = sorted(df_grouped[\"fiscal_year\"].unique())"
      ],
      "id": "bf2a4bf8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49e90af4"
      },
      "source": [
        "**Reasoning**:\n",
        "Plot the grouped bar chart for net income comparison across companies using the processed data, following the remaining instructions for plotting and labeling.\n",
        "\n"
      ],
      "id": "49e90af4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "083fee6d"
      },
      "source": [
        "# Set bar width\n",
        "bar_width = 0.15\n",
        "x = np.arange(len(years))  # positions for fiscal years\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Plot each company‚Äôs bars\n",
        "for i, company in enumerate(companies):\n",
        "    company_data = df_grouped[df_grouped[\"company_name\"] == company]\n",
        "    net_incomes = [company_data[company_data[\"fiscal_year\"] == y][\"net_income_millions\"].sum() for y in years]\n",
        "    plt.bar(x + i*bar_width, net_incomes, width=bar_width, label=f\"{company} Net Income\")\n",
        "\n",
        "plt.xticks(x + bar_width*(len(companies)-1)/2, years)\n",
        "plt.xlabel(\"Fiscal Year\")\n",
        "plt.ylabel(\"¬£ Millions\")\n",
        "plt.title(\"Net Income Comparison Across Companies\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "083fee6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bdbb832"
      },
      "source": [
        "## Analyze total assets\n",
        "\n",
        "### Subtask:\n",
        "Visualize and compare the total assets of each company over time to understand their growth and scale.\n"
      ],
      "id": "0bdbb832"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5db3858"
      },
      "source": [
        "**Reasoning**:\n",
        "Filter the dataframe to include only annual reports and group by company and fiscal year to calculate the sum of total assets.\n",
        "\n"
      ],
      "id": "a5db3858"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d0eb005"
      },
      "source": [
        "# Filter only annual reports\n",
        "df_filtered = df_metrics[df_metrics[\"report_type\"].str.lower() == \"annual\"]\n",
        "\n",
        "# Group by company and year\n",
        "df_grouped = df_filtered.groupby([\"company_name\", \"fiscal_year\"])[\n",
        "    \"total_assets_millions\"\n",
        "].sum().reset_index()"
      ],
      "id": "7d0eb005",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8f0b19b"
      },
      "source": [
        "**Reasoning**:\n",
        "Get the unique company names and sorted fiscal years from the grouped dataframe and set up the plotting parameters.\n",
        "\n"
      ],
      "id": "b8f0b19b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96c73ffe"
      },
      "source": [
        "# Get unique values\n",
        "companies = df_grouped[\"company_name\"].unique().tolist()\n",
        "years = sorted(df_grouped[\"fiscal_year\"].unique())\n",
        "\n",
        "# Set bar width\n",
        "bar_width = 0.15\n",
        "x = np.arange(len(years))  # positions for fiscal years"
      ],
      "id": "96c73ffe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af5c47d3"
      },
      "source": [
        "**Reasoning**:\n",
        "Plot a grouped bar chart to visualize the total assets for each company across the fiscal years.\n",
        "\n"
      ],
      "id": "af5c47d3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39c3702a"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Plot each company‚Äôs bars\n",
        "for i, company in enumerate(companies):\n",
        "    company_data = df_grouped[df_grouped[\"company_name\"] == company]\n",
        "    total_assets = [company_data[company_data[\"fiscal_year\"] == y][\"total_assets_millions\"].sum() for y in years]\n",
        "    plt.bar(x + i*bar_width, total_assets, width=bar_width, label=f\"{company} Total Assets\")\n",
        "\n",
        "plt.xticks(x + bar_width*(len(companies)-1)/2, years)  # Center ticks\n",
        "plt.xlabel(\"Fiscal Year\")\n",
        "plt.ylabel(\"¬£ Millions\")\n",
        "plt.title(\"Total Assets Comparison Across Companies\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "39c3702a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7edf1ecb"
      },
      "source": [
        "## Analyze employee count\n",
        "\n",
        "### Subtask:\n",
        "Compare the employee counts across companies to understand their workforce size.\n"
      ],
      "id": "7edf1ecb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c93e0cb"
      },
      "source": [
        "**Reasoning**:\n",
        "Filter the DataFrame to include only annual reports and group by company and fiscal year to get the sum of employee counts.\n",
        "\n"
      ],
      "id": "3c93e0cb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0c3e892"
      },
      "source": [
        "# Filter only annual reports\n",
        "df_filtered_employees = df_metrics[df_metrics[\"report_type\"].str.lower() == \"annual\"]\n",
        "\n",
        "# Group by company and year\n",
        "df_grouped_employees = df_filtered_employees.groupby([\"company_name\", \"fiscal_year\"])[\n",
        "    \"employee_count\"\n",
        "].sum().reset_index()"
      ],
      "id": "b0c3e892",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caa1af2f"
      },
      "source": [
        "**Reasoning**:\n",
        "Get the unique company names and sorted fiscal years, then create a bar chart to visualize the employee count for each company across the fiscal years, setting the labels and title as specified in the instructions.\n",
        "\n"
      ],
      "id": "caa1af2f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83a77263"
      },
      "source": [
        "# Get unique values\n",
        "companies_employees = df_grouped_employees[\"company_name\"].unique().tolist()\n",
        "years_employees = sorted(df_grouped_employees[\"fiscal_year\"].unique())\n",
        "\n",
        "# Set bar width\n",
        "bar_width_employees = 0.15\n",
        "x_employees = np.arange(len(years_employees))  # positions for fiscal years\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Plot each company‚Äôs bars\n",
        "for i, company in enumerate(companies_employees):\n",
        "    company_data = df_grouped_employees[df_grouped_employees[\"company_name\"] == company]\n",
        "    employee_counts = [company_data[company_data[\"fiscal_year\"] == y][\"employee_count\"].sum() for y in years_employees]\n",
        "    plt.bar(x_employees + i*bar_width_employees, employee_counts, width=bar_width_employees, label=f\"{company} Employee Count\")\n",
        "\n",
        "plt.xticks(x_employees + bar_width_employees*(len(companies_employees)-1)/2, years_employees)  # Center ticks\n",
        "plt.xlabel(\"Fiscal Year\")\n",
        "plt.ylabel(\"Employee Count\")\n",
        "plt.title(\"Employee Count Comparison Across Companies\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "83a77263",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "566a573b"
      },
      "source": [
        "## Analyze esg metrics (ghg emissions)\n",
        "\n",
        "### Subtask:\n",
        "Visualize and compare the Scope 1, Scope 2, Scope 3, and Total GHG emissions for companies that have sustainability reports available.\n"
      ],
      "id": "566a573b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7efbb752"
      },
      "source": [
        "**Reasoning**:\n",
        "Filter the DataFrame to include only sustainability reports and then group by company and fiscal year to sum the GHG emissions columns.\n",
        "\n"
      ],
      "id": "7efbb752"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "225cfcc1"
      },
      "source": [
        "# Filter only sustainability reports\n",
        "df_filtered_esg = df_metrics[df_metrics[\"report_type\"].str.lower() == \"sustainability\"]\n",
        "\n",
        "# Group by company and year and sum GHG emission columns\n",
        "df_grouped_esg = df_filtered_esg.groupby([\"company_name\", \"fiscal_year\"])[\n",
        "    [\"scope_1_ghg_emissions\", \"scope_2_ghg_emissions\", \"scope_3_ghg_emissions\", \"total_ghg_emissions\"]\n",
        "].sum().reset_index()"
      ],
      "id": "225cfcc1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ec894a"
      },
      "source": [
        "**Reasoning**:\n",
        "Get the unique company names and sorted fiscal years from the grouped ESG data and then iterate through each company to create a multi-line plot for their GHG emissions over the years.\n",
        "\n"
      ],
      "id": "c3ec894a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "722132b6"
      },
      "source": [
        "# Get unique values\n",
        "companies_esg = df_grouped_esg[\"company_name\"].unique().tolist()\n",
        "years_esg = sorted(df_grouped_esg[\"fiscal_year\"].unique())\n",
        "\n",
        "# Plot GHG emissions for each company\n",
        "for company in companies_esg:\n",
        "    company_data_esg = df_grouped_esg[df_grouped_esg[\"company_name\"] == company]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(company_data_esg[\"fiscal_year\"], company_data_esg[\"scope_1_ghg_emissions\"], marker=\"o\", label=\"Scope 1 GHG Emissions\")\n",
        "    plt.plot(company_data_esg[\"fiscal_year\"], company_data_esg[\"scope_2_ghg_emissions\"], marker=\"o\", label=\"Scope 2 GHG Emissions\")\n",
        "    plt.plot(company_data_esg[\"fiscal_year\"], company_data_esg[\"scope_3_ghg_emissions\"], marker=\"o\", label=\"Scope 3 GHG Emissions\")\n",
        "    plt.plot(company_data_esg[\"fiscal_year\"], company_data_esg[\"total_ghg_emissions\"], marker=\"o\", label=\"Total GHG Emissions\")\n",
        "\n",
        "    plt.xlabel(\"Fiscal Year\")\n",
        "    plt.ylabel(\"GHG Emissions (tonnes)\")\n",
        "    plt.title(f\"GHG Emissions Trends for {company}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "id": "722132b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b292787"
      },
      "source": [
        "## Identify correlations\n",
        "\n",
        "### Subtask:\n",
        "Explore potential correlations between financial metrics (like revenue and net income) and ESG metrics (like GHG emissions) if applicable data is available for the same years and companies.\n"
      ],
      "id": "6b292787"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-TsgvKkNdx-"
      },
      "source": [
        "# Convert BigFrames DataFrames to pandas DataFrames\n",
        "df_filtered_pandas = df_filtered.to_pandas()\n",
        "df_filtered_esg_pandas = df_filtered_esg.to_pandas()\n",
        "\n",
        "# Merge the financial and ESG dataframes\n",
        "df_merged = pd.merge(df_filtered_pandas, df_filtered_esg_pandas, on=['company_name', 'fiscal_year'], how='inner', suffixes=('_financial', '_esg'))\n",
        "\n",
        "# Select relevant numerical columns for correlation analysis\n",
        "correlation_cols = [\n",
        "    'revenue_millions_financial',\n",
        "    'net_income_millions_financial',\n",
        "    'scope_1_ghg_emissions_esg',\n",
        "    'scope_2_ghg_emissions_esg',\n",
        "    'scope_3_ghg_emissions_esg',\n",
        "    'total_ghg_emissions_esg'\n",
        "]\n",
        "\n",
        "# Filter out rows with -1 values in the selected columns before calculating correlation\n",
        "df_correlation = df_merged[~(df_merged[correlation_cols] == -1).any(axis=1)]\n",
        "\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df_correlation[correlation_cols].corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix: Financial vs. ESG Metrics\")\n",
        "plt.show()"
      ],
      "id": "e-TsgvKkNdx-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9396996"
      },
      "source": [
        "## Summarize key findings\n",
        "\n",
        "### Subtask:\n",
        "Present a summary of the key insights gained from the analysis of the different metrics.\n"
      ],
      "id": "d9396996"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "455185a3"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the outputs from the previous analysis steps, focusing on the visualizations and key findings for net income, total assets, employee count, and GHG emissions, and the correlation analysis. Write a concise summary highlighting the most significant trends and comparisons observed across the companies for each analyzed metric, including any notable observations about the relationships (or lack thereof) between financial and ESG metrics. Structure the summary logically.\n",
        "\n"
      ],
      "id": "455185a3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ad54649"
      },
      "source": [
        "print(\"## Key Insights from Financial and ESG Analysis\")\n",
        "print(\"\\n### Financial Performance (Revenue and Net Income)\")\n",
        "print(\"The analysis of revenue and net income across the selected companies (Bank of Montreal, JPMorgan Chase, and Wells Fargo) over the available fiscal years reveals significant differences in scale. JPMorgan Chase consistently reports the highest revenue and net income, reflecting its position as a larger financial institution compared to Bank of Montreal and Wells Fargo. While all companies show fluctuations in these metrics over time, the overall trend for JPMorgan Chase appears to be upward in terms of revenue. Bank of Montreal and Wells Fargo show more varied patterns in net income.\")\n",
        "\n",
        "print(\"\\n### Total Assets\")\n",
        "print(\"Comparing the total assets provides further insight into the scale of these financial institutions. Similar to revenue and net income, JPMorgan Chase has substantially higher total assets than Bank of Montreal and Wells Fargo. The trends in total assets generally show growth over the years for all companies, indicating expansion and increased balance sheet size.\")\n",
        "\n",
        "print(\"\\n### Employee Count\")\n",
        "print(\"The employee count analysis indicates the workforce size of each company. JPMorgan Chase has a significantly larger employee base compared to Bank of Montreal and Wells Fargo, aligning with its larger scale in terms of revenue and assets. The employee counts for all companies show some year-to-year variation, which could be influenced by factors such as hiring, divestitures, or acquisitions.\")\n",
        "\n",
        "print(\"\\n### Environmental Performance (GHG Emissions)\")\n",
        "print(\"Analyzing the GHG emissions (Scope 1, 2, 3, and Total) from the available sustainability reports provides insights into the environmental footprint of the companies. The data for GHG emissions is less consistently available across companies and years compared to financial data. For the data that is available, there are variations in the reported emission levels and trends across the companies. It's important to note that reporting methodologies and scope coverage can differ between companies and years, which can impact direct comparisons.\")\n",
        "\n",
        "print(\"\\n### Correlation between Financial and ESG Metrics\")\n",
        "print(\"The correlation analysis between selected financial metrics (revenue, net income) and ESG metrics (GHG emissions) revealed weak or negligible linear relationships based on the available data. This suggests that, within this dataset and for these specific metrics, there is no strong direct correlation between a company's financial performance (as measured by revenue and net income) and its reported GHG emissions. This could be due to various factors, including the nature of the financial services industry, the specific reporting boundaries, or the complexity of the relationship between financial performance and environmental impact.\")\n",
        "\n",
        "print(\"\\n## Overall Insights\")\n",
        "print(\"Overall, the analysis highlights the difference in scale among the three financial institutions, with JPMorgan Chase being the largest in terms of revenue, net income, and total assets. The financial metrics generally show growth over time. The ESG data, specifically GHG emissions, provides a glimpse into the environmental considerations reported by these companies, although data availability and comparability can be limitations. The correlation analysis did not indicate a strong linear relationship between the selected financial and ESG metrics in this dataset.\")"
      ],
      "id": "4ad54649",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f501fa92"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Net Income:** JPMorgan Chase consistently reported the highest net income among the analyzed companies (Bank of Montreal, JPMorgan Chase, and Wells Fargo).\n",
        "*   **Total Assets:** JPMorgan Chase had substantially higher total assets compared to Bank of Montreal and Wells Fargo, with all companies generally showing growth in total assets over the analyzed years.\n",
        "*   **Employee Count:** JPMorgan Chase maintained a significantly larger employee base than Bank of Montreal and Wells Fargo.\n",
        "*   **GHG Emissions:** Analysis of available sustainability reports showed variations in reported GHG emission levels and trends across companies, but data availability and reporting methodology differences posed limitations to direct comparison.\n",
        "*   **Correlations:** Weak or negligible linear correlations were observed between selected financial metrics (revenue, net income) and GHG emissions (Scope 1, 2, 3, and total emissions) based on the available data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Investigate the reasons for fluctuations in net income and employee counts for Bank of Montreal and Wells Fargo.\n",
        "*   Explore alternative methods for comparing ESG metrics across companies, considering differences in reporting standards and data availability, potentially focusing on intensity metrics or normalized data.\n"
      ],
      "id": "f501fa92"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}